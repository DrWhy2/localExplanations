
@article{ribeiro_why_2016,
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {https://arxiv.org/abs/1602.04938},
	language = {en},
	urldate = {2018-10-15},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = feb,
	year = {2016},
	keywords = {lokalne},
	file = {Full Text PDF:C\:\\Users\\mstaniak\\Zotero\\storage\\CIBWE3BG\\Ribeiro i in. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf;Snapshot:C\:\\Users\\mstaniak\\Zotero\\storage\\MU99CPY9\\1602.html:text/html}
}

@article{laugel_defining_2018,
	title = {Defining {Locality} for {Surrogates} in {Post}-hoc {Interpretablity}},
	url = {http://arxiv.org/abs/1806.07498},
	abstract = {Local surrogate models, to approximate the local decision boundary of a black-box classifier, constitute one approach to generate explanations for the rationale behind an individual prediction made by the back-box. This paper highlights the importance of defining the right locality, the neighborhood on which a local surrogate is trained, in order to approximate accurately the local black-box decision boundary. Unfortunately, as shown in this paper, this issue is not only a parameter or sampling distribution challenge and has a major impact on the relevance and quality of the approximation of the local black-box decision boundary and thus on the meaning and accuracy of the generated explanation. To overcome the identified problems, quantified with an adapted measure and procedure, we propose to generate surrogate-based explanations for individual predictions based on a sampling centered on particular place of the decision boundary, relevant for the prediction to be explained, rather than on the prediction itself as it is classically done. We evaluate the novel approach compared to state-of-the-art methods and a straightforward improvement thereof on four UCI datasets.},
	language = {en},
	urldate = {2018-10-17},
	journal = {arXiv:1806.07498 [cs, stat]},
	author = {Laugel, Thibault and Renard, Xavier and Lesot, Marie-Jeanne and Marsala, Christophe and Detyniecki, Marcin},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.07498},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Laugel i in. - 2018 - Defining Locality for Surrogates in Post-hoc Inter.pdf:C\:\\Users\\mstaniak\\Zotero\\storage\\5D6LQ7UB\\Laugel i in. - 2018 - Defining Locality for Surrogates in Post-hoc Inter.pdf:application/pdf}
}

@article{staniak_explanations_2018,
	title = {Explanations of model predictions with live and {breakDown} packages},
	url = {http://arxiv.org/abs/1804.01955},
	abstract = {Complex models are commonly used in predictive modeling. In this paper we present R packages that can be used for explaining predictions from complex black box models and attributing parts of these predictions to input features. We introduce two new approaches and corresponding packages for such attribution, namely live and breakDown. We also compare their results with existing implementations of state-of-the-art solutions, namely lime that implements Locally Interpretable Model-agnostic Explanations and ShapleyR that implements Shapley values.},
	language = {en},
	urldate = {2018-11-24},
	journal = {arXiv:1804.01955 [cs, stat]},
	author = {Staniak, Mateusz and Biecek, Przemyslaw},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.01955},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Applications},
	file = {Staniak i Biecek - 2018 - Explanations of model predictions with live and br.pdf:C\:\\Users\\mstaniak\\Zotero\\storage\\QBJTHR63\\Staniak i Biecek - 2018 - Explanations of model predictions with live and br.pdf:application/pdf}
}