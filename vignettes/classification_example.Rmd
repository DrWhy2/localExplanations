---
title: "Explaining classification models with localModel package"
author: "Mateusz Staniak"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Explaining classification models with localModel package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r ex}
library(DALEX)
library(randomForest)
library(localModel)

data('HR')
HR$evaluation <- as.factor(as.character(HR$evaluation))
mrf <- randomForest(status ~., data = HR, ntree = 100)

explainer <- explain(mrf, 
                     HR[, -6],
                     HR$status,
                     predict_function = function(x, y)
                       as.data.frame(predict(x, y, type = "prob")))
# DALEX2: explainer nie wymaga predict_function dla RF
# Lepsze rozwiązanie, żeby podać y w par. data:
# https://github.com/ModelOriented/ceterisParibus2/blob/master/R/ceteris_paribus.R
#

new_observation <- HR[10, -6]
size <- 500

model_lok <- individual_surrogate_model(explainer, new_observation, size, 
                                        grid_points = 100)
# Ew. usunąć zbędne zależności dla stabilności
# cutTree zamiast optimalPartition
# lime pokazuje tylko jeden przedział dla danej zmiennej
# zaznaczyć, która z wartości była w danych
# różne modele, różne cechy, różne poziomy odpowiedzi mają różne interpretowalne cechy
plot(model_lok)
```
